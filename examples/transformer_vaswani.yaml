arch:
  d_model: 512
  n_layers: 6
  norm: LayerNorm
  mix_unit:
    kind: "single"
    mixer:
      kind: "Attention"
      heads: 8
      groups: 8
      pos: "rope"
      stencil: { kind: "full" }
  ffn: { kind: "dense", mult: 4.0, act: "relu" }
  pos: { kind: "rope", rope: { theta: 10000, dims: 64 } }
  kv_policy: { cache: "full" }
train:
  ctx_len: 512
  dtype: fp16
  vocab_size: 32000

